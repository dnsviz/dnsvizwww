#!/usr/bin/env python
#
# This file is a part of DNSViz, a tool suite for DNS/DNSSEC monitoring,
# analysis, and visualization.
# Created by Casey Deccio (casey@deccio.net)
#
# Copyright 2014-2015 VeriSign, Inc.
# 
# DNSViz is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# DNSViz is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
#

import codecs
import collections
import datetime
import getopt
import json
import logging
import sys
import multiprocessing
import multiprocessing.managers
import Queue
import signal
import threading
import time

import dns.name

import django
from django.conf import settings

from dnsvizwww.analysis import Analyst, OnlineDomainNameAnalysis
from dnsvizwww.models import DomainName
from dnsviz.analysis import get_client_addresses, NetworkConnectivityException, resolver
import dnsviz.format as fmt

django.setup()

logger = logging.getLogger('dnsviz.analysis')

#XXX this is a hack required for inter-process sharing of dns.name.Name
# instances using multiprocess
def _setattr_dummy(self, name, value):
    return super(dns.name.Name, self).__setattr__(name, value)
dns.name.Name.__setattr__ = _setattr_dummy

def _raise_eof(signum, frame):
    # EOFError is raised instead of KeyboardInterrupt
    # because the multiprocessing worker doesn't handle
    # KeyboardInterrupt
    raise EOFError

def _init_interrupt_handler():
    signal.signal(signal.SIGINT, _raise_eof)

def _analyze((cls, name, dlv_domain, client_ipv4, client_ipv6, force_ancestry, start_time)):
    try:
        a = cls(name, dlv_domain=dlv_domain, client_ipv4=client_ipv4, client_ipv6=client_ipv6, start_time=start_time, force_ancestry=force_ancestry)
        a.analyze()
    # re-raise a KeyboardInterrupt, as this means we've been interrupted
    except KeyboardInterrupt:
        raise
    # don't report EOFError, as that is what is raised if there is a
    # KeyboardInterrupt in ParallelAnalyst
    except EOFError:
        pass
    except:
        logger.exception('Error analyzing %s' % name.canonicalize().to_text())

class BulkAnalyst(object):
    analyst_cls = Analyst

    def __init__(self, force_ancestry, dlv_domain):
        self.client_ipv4, self.client_ipv6 = get_client_addresses()
        if self.client_ipv4 is None and self.client_ipv6 is None:
            raise NetworkConnectivityException('No network interfaces available for analysis!')
        self.force_ancestry = force_ancestry
        self.dlv_domain = dlv_domain

        self.start_time = datetime.datetime.now(fmt.utc).replace(microsecond=0)

    def _name_to_args_iter(self, names):
        for name in names:
            yield (self.analyst_cls, name, self.dlv_domain, self.client_ipv4, self.client_ipv6, self.force_ancestry, self.start_time)

    def analyze(self, names):
        for args in self._name_to_args_iter(names):
            _analyze(args)

class MultiProcessAnalyst(Analyst):
    analysis_model = OnlineDomainNameAnalysis

class ParallelAnalyst(BulkAnalyst):
    analyst_cls = MultiProcessAnalyst

    def __init__(self, force_ancestry, dlv_domain, processes):
        super(ParallelAnalyst, self).__init__(force_ancestry, dlv_domain)
        self.manager = multiprocessing.managers.SyncManager()
        self.manager.start()

        self.processes = processes

    def analyze(self, names):
        results = []
        pool = multiprocessing.Pool(self.processes, _init_interrupt_handler, maxtasksperchild=50)
        try:
            for args in self._name_to_args_iter(names):
                while pool._taskqueue.full():
                    time.sleep(0.5)
                results.append(pool.apply_async(_analyze, (args,)))
            # loop instead of just joining, so we can check for interrupt at
            # main process
            for result in results:
                result.wait()
        except KeyboardInterrupt:
            pool.terminate()
            raise

        pool.close()
        pool.join()

    def refresh(self):
        wait_time = 60
        last_refresh_offsets = {}

        last_stats = 0
        stats_interval = 1800
        refreshed = 0

        pool = multiprocessing.Pool(self.processes, _init_interrupt_handler, maxtasksperchild=50)
        try:
            while True:
                refresh_intervals = set(DomainName.objects.filter(refresh_interval__isnull=False).values_list('refresh_interval', flat=True).distinct())

                # synchronize refresh_intervals and last_refresh_offsets
                for i in set(last_refresh_offsets).union(refresh_intervals):
                    if i not in last_refresh_offsets:
                        last_refresh_offsets[i] = None
                    if i not in refresh_intervals:
                        del last_refresh_offsets[i]

                # at the start of every loop check for names being analyzed
                start = int(time.time())
                timestamp = datetime.datetime.now(fmt.utc).replace(microsecond=0)
                tot = 0
                for interval, last_offset in last_refresh_offsets.items():
                    offset = DomainName.objects.offset_for_interval(interval)
                    if last_offset is not None:
                        names_to_refresh = set(map(dns.name.from_text, DomainName.objects.names_to_refresh(interval, offset, last_offset).values_list('name', flat=True)))

                        for args in self._name_to_args_iter(names_to_refresh):
                            while pool._taskqueue.full():
                                time.sleep(0.5)
                            pool.apply_async(_analyze, (args,))

                        refreshed += len(names_to_refresh)
                    last_refresh_offsets[interval] = offset

                end = int(time.time())
                elapsed = end - start
                if elapsed < wait_time:
                    time.sleep(wait_time - elapsed)
                time_since_stats = end - last_stats
                if time_since_stats >= stats_interval:
                    now = datetime.datetime.now(fmt.utc).replace(microsecond=0)
                    last_stats = end
                    logger.warning('%s: (refreshed: %d; taskqueue: %d) ' % (now, refreshed, pool._taskqueue.qsize()))
                    refreshed = 0

        except KeyboardInterrupt:
            pool.terminate()

        pool.close()
        pool.join()

def usage():
    sys.stderr.write('''Usage: %s [ options ] ( -R | -f <filename> | <domain name> [... ] )

Options:
    -f <filename>  - read names from a file (one name per line), instead of from command line
    -d <level>     - set debug level to a value from 0 to 3, with increasing verbosity (default: 2 or INFO)
    -l <dlv>       - use dlv as a domain for DNSSEC look-aside validation
    -R             - refresh names on a periodic basis
    -t <threads>   - use multiple threads for analysis
    -F             - force analysis of ancestry, instead of relying on cached versions
''' % sys.argv[0])

def main():
    try:
        try:
            opts, args = getopt.getopt(sys.argv[1:], 'f:d:l:Rt:F')
        except getopt.GetoptError:
            usage()
            sys.exit(1)

        opts = dict(opts)
        if ('-f' in opts and args) or ('-R' in opts and args) or ('-f' in opts and '-R' in opts) or \
                not ('-f' in opts or '-R' in opts or args):
            usage()
            sys.exit(1)

        if '-l' in opts:
            dlv_domain = dns.name.from_text(opts['-l'])
        else:
            dlv_domain = None

        force_ancestry = '-F' in opts

        try:
            processes = int(opts.get('-t', 1))
        except ValueError:
            usage()
            sys.exit(1)
        if processes < 1:
            usage()
            sys.exit(1)

        try:
            val = int(opts.get('-d', 2))
        except ValueError:
            usage()
            sys.exit(1)

        if val < 0 or val > 3:
            usage()
            sys.exit(1)

        if val > 2:
            debug_level = logging.DEBUG
        elif val > 1:
            debug_level = logging.INFO
        elif val > 0:
            debug_level = logging.WARNING
        else:
            debug_level = logging.ERROR
        has_handler = False
        # check if there's already a StreamHandler that allows messages through the
        # filters by default
        for handler in logger.handlers:
            if isinstance(handler, logging.StreamHandler):
                if False not in [f.filter(None) for f in handler.filters]:
                    has_handler = True
                    break
        if not has_handler:
            handler = logging.StreamHandler()
            handler.setLevel(debug_level)
            logger.addHandler(handler)
        logger.setLevel(debug_level)

        if '-f' in opts:
            names = []
            with codecs.open(opts['-f'], 'r', 'utf-8') as f:
                for line in f:
                    try:
                        name = dns.name.from_unicode(line.strip())
                    except UnicodeDecodeError, e:
                        logger.warning('%s: %s' % (line.strip(), e))
                        continue

                    # check against refresh blacklist
                    blacklisted = False
                    for black in settings.BLACKLIST_FROM_REFRESH:
                        if name.is_subdomain(black):
                            blacklisted = True
                            break
                    if blacklisted:
                        continue

                    names.append(name)
        else:
            names = map(dns.name.from_text, args)

        name_objs = []
        if '-R' in opts:
            a = ParallelAnalyst(force_ancestry, dlv_domain, processes)
            a.refresh()
        else:
            if '-t' in opts:
                a = ParallelAnalyst(force_ancestry, dlv_domain, processes)
            else:
                a = BulkAnalyst(force_ancestry, dlv_domain)
            name_objs = a.analyze(names)

    except KeyboardInterrupt:
        logger.error('Interrupted.')
        sys.exit(4)

if __name__ == "__main__":
    main()
